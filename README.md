# CrawlScheduler
사이트를 크롤링하는 스케쥴러

## 소개
CrawlScheduler는 다양한 커뮤니티 사이트에서 게시물을 크롤링하고, 이를 데이터베이스에 저장하는 스케줄러입니다. 이 프로젝트는 Ygosu, Ppomppu 사이트를 대상으로 하며, 향후 추가될 예정입니다.

## 기능
- **실시간 베스트 게시물 수집**: 실시간 베스트 게시물을 크롤링하여 데이터베이스에 저장합니다.
- **게시물 내용 수집**: 게시물의 내용을 이미지, 비디오, 텍스트 형식으로 수집합니다.

## 사용 방법
1. **환경 설정**: 필요한 라이브러리를 설치합니다.
   ```bash
   poetry install
   ```

2. **데이터베이스 설정**: MongoDB와 같은 데이터베이스를 설정하고 연결합니다.

3. **스크립트 실행**: 아래 명령어로 스크립트를 실행하여 크롤링을 시작합니다.
   ```bash
   dev.sh
   ```

## 파일 구조
crawl_scheduler/

│

├── community_website/

│ ├── ygosu.py # Ygosu 사이트 크롤러

│ ├── ppomppu.py # Ygosu 사이트 크롤러

│

├── db/

│ ├── mongo_controller.py # MongoDB와의 상호작용을 위한 컨트롤러

│

├── constants.py # 상수 정의

│

├── utils/

│ ├── loghandler.py # 로깅 핸들러

│

└── main.py # 메인 실행 파일


## MongoDB 인덱싱
MongoDB에서 인덱싱은 데이터 검색 성능을 향상시키기 위해 사용됩니다. 인덱스는 데이터베이스의 특정 필드에 대한 포인터를 생성하여, 쿼리 성능을 개선합니다. 인덱스를 사용하면 대량의 데이터에서 원하는 정보를 더 빠르게 찾을 수 있습니다. 예를 들어, 게시물의 작성 날짜나 작성자에 대한 인덱스를 생성하면 해당 필드로 검색할 때 성능이 크게 향상됩니다.

Category, No로 indexing을 세분화 했습니다.


## 기여
기여를 원하시는 분은 이 저장소를 포크한 후, 변경 사항을 제안해 주세요. 

## 라이센스
이 프로젝트는 MIT 라이센스 하에 배포됩니다.
